import os
import psycopg2
import json
import time
from filters_json import filter_list as FilterMap

QUERY_STRINGS = {}
DB_CONFIG = {}


def init():
    _init_db_config()
    _build_query_strings()


def _build_connection_string():
    connection_string = []
    connection_string.append("host=" + DB_CONFIG['DB_HOST'])
    connection_string.append("dbname=" + DB_CONFIG['DB_NAME'])
    connection_string.append("user=" + DB_CONFIG['DB_USERNAME'])
    connection_string.append("password=" + DB_CONFIG['DB_PASSWORD'])
    return " ".join(connection_string)


def _init_db_config():
    r_config = os.environ.get('R_CONFIG')
    if r_config == 'Prod':
        DB_CONFIG['DB_HOST'] = os.environ.get('R_DB_HOST')
        DB_CONFIG['DB_NAME'] = os.environ.get('R_DB_NAME')
        DB_CONFIG['DB_USERNAME'] = os.environ.get('R_DB_USERNAME')
        DB_CONFIG['DB_PASSWORD'] = os.environ.get('R_DB_PASSWORD')
    elif r_config == 'Test':
        DB_CONFIG['DB_HOST'] = os.environ.get('R_TEST_DB_HOST')
        DB_CONFIG['DB_NAME'] = os.environ.get('R_TEST_DB_NAME')
        DB_CONFIG['DB_USERNAME'] = os.environ.get('R_TEST_DB_USERNAME')
        DB_CONFIG['DB_PASSWORD'] = os.environ.get('R_TEST_DB_PASSWORD')
    else:
        raise Exception("R_CONFIG not set.")

    DB_CONFIG['DB_CONNECTION_STRING'] = _build_connection_string()


def _build_query_strings():
    QUERY_STRINGS['fetch_chart1'] = _build_q1_query()
    QUERY_STRINGS['fetch_chart2'] = _build_q2_query()
    QUERY_STRINGS['ticker1'] = _build_q3_query()
    QUERY_STRINGS['geomap1'] = _build_q4_query()

    QUERY_STRINGS['save_tweet'] = _build_save_tweet_sql()

    QUERY_STRINGS['save_tweets']= _save_tweets()
    QUERY_STRINGS['save_filters'] = _save_filters()
    QUERY_STRINGS['save_users'] = _save_users()
    QUERY_STRINGS['save_user_filter_join'] = save_user_filter_join()
    QUERY_STRINGS['find_row'] = _find_row()
    QUERY_STRINGS['find_user'] = _find_user()
    QUERY_STRINGS['find_filter'] = _find_filter()
    QUERY_STRINGS['find_join'] = _find_join()
    QUERY_STRINGS['update_user_tw_count'] = _update_user_tweet_count()
    QUERY_STRINGS['update_filter_tw_count'] = _update_filter_tweet_count()
    QUERY_STRINGS['update_join_tw_count'] = _update_join_tweet_count()
    QUERY_STRINGS['update_user_timestamp'] = _update_user_timestamp()
    QUERY_STRINGS['update_filter_timestamp'] = _update_filter_timestamp()
    QUERY_STRINGS['update_join_timestamp'] = _update_join_timestamp()
    QUERY_STRINGS['get_tw_count'] = _get_tweet_count()
    QUERY_STRINGS['fetch_filter_tw_counts'] = _query_filter_tweets_counts()
    QUERY_STRINGS['fetch_popular_users'] = _query_popular_users()
    QUERY_STRINGS['tweet_ids'] = _query_tweet_ids()


def _connect_db():
    try:
        print "establishing a new connection..."
        conn = psycopg2.connect(DB_CONFIG['DB_CONNECTION_STRING'])
    except Exception as x:
        raise Exception("Error connecting to DB: " + str(x.args))
    print "Connection established and stored..."
    DB_CONFIG['DB_CONNECTION'] = conn
    return conn


def _get_connection():
    """get the current connection if it exists, else connect."""
    conn = DB_CONFIG.get('DB_CONNECTION')
    if conn is not None:
        print "connection exists, so reusing it..."
        return conn
    else:
        print "no connection found..."
        return _connect_db()


def _create_cursor():
    """create a new cursor and store it"""
    conn = _get_connection()
    print "creating new cursor..."
    DB_CONFIG['DB_CURSOR'] = conn.cursor()
    print "got new cursor."
    return DB_CONFIG['DB_CURSOR']


def _get_cursor():
    """get the current cursor if it exist, else create a new cursor"""
    cur = DB_CONFIG.get('DB_CURSOR')
    if cur is not None:
        print "cursor exists, using that..."
        return cur
    else:
        print "no cursor found, so creating one..."
        return _create_cursor()


def _execute_query(sql, args=None, need_fetch=True, need_dump = True):
    """execute the passed in SQL using the current cursor.
    If the query string takes any args pass those to the cursor as well."""
    try:
        print "getting cursor..."
        cur = _get_cursor()
        print "executing the following on cursor:"
        print "SQL STRING: {}".format(sql)
        print "SQL ARGS: {}".format(args)
        cur.execute(sql, args)
        if need_fetch:
            print "Getting results..."
            results = cur.fetchall()
            print results
            if not need_dump:
                return results
            print "Got results..."
            try:
                json_results = json.dumps(results)
            except Exception as x:
                print "Error dumping json for: ", results, " Args: ", x.args
            else:
                return json_results
    except psycopg2.Error as x:
        # this will catch any errors generated by the database
        print "*" * 40
        print "Error execuring query against DB: ", x.args
        print "Attempting to reconnect to the DB..."
        DB_CONFIG['DB_CONNECTION'].close()
        DB_CONFIG['DB_CONNECTION'] = None
        DB_CONFIG['DB_CURSOR'] = None
        time.sleep(5)
        conn = _get_connection()
        while conn is None:
            conn = _get_connection()
            time.sleep(5)
    else:
        DB_CONFIG['DB_CONNECTION'].commit()
    return None


def _build_q1_query():
    """build a query string for Q1 using FilterMap"""
    sql = []
    args = []
    sql.append("""SELECT hashtag, COUNT(hashtag) as HashTagCount""")
    sql.append("""FROM (SELECT screen_name, unnest(hashtags) as hashtag FROM massive) as subquery""")
    sql.append("""WHERE""")
    for language in FilterMap:
        search_terms = FilterMap[language]['search_terms']
        for hashtag in search_terms['hashtags']:
            sql.append("""hashtag = %s """)
            args.append(hashtag[1:])
            sql.append("""OR""")
    sql.pop()  # discard last OR statement
    sql.append("""GROUP BY hashtag""")
    sql.append("""ORDER BY HashTagCount DESC""")
    return (" \r\n".join(sql), args)


def _build_q2_query():
    """build a query string for Q2 using FilterMap"""
    sql = []
    args = []
    sql.append("""SELECT hashtag, HashTagCount, screen_name""")
    sql.append("""FROM (SELECT hashtag, screen_name, HashTagCount, rank() OVER (PARTITION BY hashtag ORDER BY HashTagCount DESC, screen_name) AS pos""")
    sql.append("""FROM (SELECT hashtag, screen_name, COUNT(hashtag) as HashTagCount""")
    sql.append("""FROM (SELECT screen_name, unnest(hashtags) as hashtag FROM massive) as unwrap""")
    sql.append("""WHERE""")
    for language in FilterMap:
        search_terms = FilterMap[language]['search_terms']
        for hashtag in search_terms['hashtags']:
            sql.append("""hashtag = %s """)
            args.append(hashtag[1:])
            sql.append("""OR""")
    sql.pop()  # discard last OR statement
    sql.append("""GROUP BY screen_name, hashtag""")
    sql.append("""ORDER BY hashtag, HashTagCount DESC""")
    sql.append(""") as countedhashtags""")
    sql.append(""") as ss""")
    sql.append("""WHERE pos = 1""")
    sql.append("""ORDER BY hashtag, HashTagCount DESC""")
    return (" \r\n".join(sql), args)


def _build_q3_query():
    sql = """
    SELECT screen_name, text FROM massive
    ORDER BY tweet_id DESC
    LIMIT 1;
    """
    return (sql, None)


def _build_save_tweet_sql():
    return ("""
            INSERT INTO massive(
                tweet_id, text, hashtags, user_mentions,
                created_at, screen_name, urls, location,
                inreplytostatusif, retweetcount)

            VALUES(
                %s, %s, %s, %s, %s, %s, %s,
                %s, %s, %s); """, [])


def _build_q4_query():
    sql = []
    sql.append("""SELECT tweet_id, text, screen_name, location FROM massive""")
    sql.append("""WHERE json_array_length(location) <> 0""")
    sql.append("""ORDER BY tweet_id DESC LIMIT 1""")
    return (" ".join(sql), None)



# New db structure queries

def _find_row():
    sql = []
    sql.append("""SELECT 1 FROM %s WHERE %s""")
    return (sql, [])

def _find_user():
    sql = ("""SELECT * FROM users WHERE screen_name = %s """)
    return (sql, [])

def _find_filter():
    sql = ("""SELECT * FROM filters WHERE filter_name = %s """)
    return (sql, [])

def _find_join():
    sql = []
    sql.append ("""SELECT * FROM user_filter_join""")
    sql.append ("""WHERE screen_name = %s AND filter_name = %s""")
    return (" ".join(sql), None)


def _get_tweet_count():
    sql=("""SELECT 1 from %s WHERE %s;""")
    return (sql, [])

def _update_user_tweet_count():
    sql = ("""UPDATE users SET tweet_count = %s WHERE screen_name = %s;""")
    return (sql, [])

def _update_user_timestamp():
    sql = ("""UPDATE users SET last_tweet_timestamp = %s WHERE screen_name = %s;""")
    return (sql, [])

def _update_filter_tweet_count():
    sql = ("""UPDATE filters SET tweet_count = %s WHERE filter_name = %s;""")
    return (sql, [])

def _update_filter_timestamp():
    sql = ("""UPDATE filters SET last_tweet_timestamp = %s WHERE filter_name = %s;""")
    return (sql, [])

def _update_join_tweet_count():
    sql = []
    sql .append("""UPDATE user_filter_join SET tweet_count = %s """)
    sql.append("""WHERE screen_name = %s AND filter_name = %s""")
    return (" ".join(sql), None)

def _update_join_timestamp():
    sql = []
    sql.append ("""UPDATE user_filter_join SET last_tweet_timestamp = %s""")
    sql.append ("""WHERE screen_name = %s AND filter_name = %s""")
    return (" ".join(sql), None)


def _query_filter_tweets_counts():
    sql = ("""SELECT filter_name, tweet_count FROM filters ORDER BY tweet_count DESC;""")
    return (sql, [])

def _query_popular_users():
    final_result = []
    sql1_result = _execute_query("""SELECT filter_name FROM filters ORDER BY tweet_count DESC""", None, True, False)
    for filter_ in sql1_result:
        tmp_sql = []
        tmp_sql.append("""SELECT filter_name, tweet_count, screen_name FROM  user_filter_join""")
        tmp_sql.append("""WHERE filter_name = %s ORDER BY tweet_count DESC LIMIT 1""")
        json_result = _execute_query(" ".join(tmp_sql), [filter_[0]])
        json_result = json_result.split(', ')
        tmp_json = []
        tmp_json.append(json_result[0][3:-1])
        tmp_json.append(int(json_result[1]))
        tmp_json.append(json_result[2][1:-3])
        if  json_result:
            final_result.append(tmp_json)

    print "---->FINAL RESULT", final_result
    return final_result

#      JSONNNN [["javascript", 18, "js_digest"]]
# FUCK RESULT [['"javascript", 18, "js_digest"'], ['"php", 5, "js_digest"']]
# PARSED RESULT [[u'BackboneJS', 10, u'js_digest'], [u'clanguage', 2, u'shafikyaghmour'], [u'cprogramming', 4, u'CouponIgnite'], [u'CSharp', 37, u'Ehickioya'], [u'Django', 8, u'_PinPoint_'], [u'Flask', 2, u'Psoriasis_Care'], [u'Java', 112, u'Java_Question'], [u'java8', 28, u'OmerJavedonline'], [u'javadeveloper', 1, u'JannaLKirkland'], [u'JavaEE', 5, u'c2b2consulting'], [u'javafx', 11, u'SoftMAS_CO'], [u'Javascript', 429, u'js_digest'], [u'JQuery', 26, u'js_digest'], [u'NodeJS', 91, u'js_digest'], [u'numpy', 2, u'KateiyaM'], [u'objectivec', 14, u'findmjob'], [u'PHP', 220, u'PHP_Quest'], [u'pyconau', 2, u'caleb_hattingh'], [u'Python', 120, u'Python_Quest'], [u'rails', 33, u'findmjob'], [u'Ruby', 88, u'MANA_fmanassero'], [u'RubyOnRails', 10, u'Sidejob_'], [u'swiftlang', 30, u'swiftLDN'], [u'VB', 32, u'VB_bingb'], [u'VBA', 18, u'Programing_Box']]
# PARSED RESULT [[u'javascript', 1, u'daaon'], [u'javascript', 1, u'findmjob'], [u'javascript', 1, u'TheIndieSloth'], [u'javascript', 1, u'mark_skeet'], [u'javascript', 1, u'trikitrok'], [u'javascript', 1, u'we_Recruit'], [u'javascript', 1, u'narinta_407'], [u'javascript', 1, u'pouya'], [u'javascript', 1, u'gummatt'], [u'javascript', 2, u'JavaEmployer'], [u'javascript', 1, u'HTML5Digest1'], [u'javascript', 1, u'kremplo'], [u'javascript', 1, u'proghu'], [u'javascript', 1, u'AdWordsJobs'], [u'javascript', 1, u'Stud_Richmond'], [u'javascript', 1, u'Go_Freelancer'], [u'javascript', 1, u'bulkanevcimen'], [u'javascript', 1, u'tonytamps'], [u'javascript', 1, u'CounilLaurent'], [u'javascript', 2, u'LissaRabinowitz'], [u'javascript', 1, u'DesignLearnBot'], [u'javascript', 1, u'Best_Gadgets_4U'], [u'javascript', 1, u'rjaviervega'], [u'javascript', 1, u'emGhost_'], [u'javascript', 18, u'js_digest'], [u'javascript', 2, u'symfony_jobs'], [u'javascript', 1, u'MVP_Armagan'], [u'javascript', 1, u'imarshut'], [u'javascript', 4, u'ameanmbot'], [u'javascript', 1, u'wp_digest'], [u'javascript', 1, u'wp_portugal'], [u'javascript', 1, u'EmotiCodeDotNet'], [u'javascript', 1, u'cveksitron'], [u'javascript', 3, u'PHPHire'], [u'javascript', 4, u'html5_4_all'], [u'javascript', 1, u'Best_WordPress_']]
# FINAL RESULT [["javascript", 1, "daaon"], ["javascript", 1, "findmjob"], ["javascript", 1, "TheIndieSloth"], ["javascript", 1, "mark_skeet"], ["javascript", 1, "trikitrok"], ["javascript", 1, "we_Recruit"], ["javascript", 1, "narinta_407"], ["javascript", 1, "pouya"], ["javascript", 1, "gummatt"], ["javascript", 2, "JavaEmployer"], ["javascript", 1, "HTML5Digest1"], ["javascript", 1, "kremplo"], ["javascript", 1, "proghu"], ["javascript", 1, "AdWordsJobs"], ["javascript", 1, "Stud_Richmond"], ["javascript", 1, "Go_Freelancer"], ["javascript", 1, "bulkanevcimen"], ["javascript", 1, "tonytamps"], ["javascript", 1, "CounilLaurent"], ["javascript", 2, "LissaRabinowitz"], ["javascript", 1, "DesignLearnBot"], ["javascript", 1, "Best_Gadgets_4U"], ["javascript", 1, "rjaviervega"], ["javascript", 1, "emGhost_"], ["javascript", 18, "js_digest"], ["javascript", 2, "symfony_jobs"], ["javascript", 1, "MVP_Armagan"], ["javascript", 1, "imarshut"], ["javascript", 4, "ameanmbot"], ["javascript", 1, "wp_digest"], ["javascript", 1, "wp_portugal"], ["javascript", 1, "EmotiCodeDotNet"], ["javascript", 1, "cveksitron"], ["javascript", 3, "PHPHire"], ["javascript", 4, "html5_4_all"], ["javascript", 1, "Best_WordPress_"]]

# FINAL RESULT ['[["javascript", 1, "daaon"], ["javascript", 1, "findmjob"], ["javascript", 1, "TheIndieSloth"], ["javascript", 1, "mark_skeet"], ["javascript", 1, "trikitrok"], ["javascript", 1, "we_Recruit"], ["javascript", 1, "narinta_407"], ["javascript", 1, "pouya"], ["javascript", 1, "gummatt"], ["javascript", 2, "JavaEmployer"], ["javascript", 1, "HTML5Digest1"], ["javascript", 1, "kremplo"], ["javascript", 1, "proghu"], ["javascript", 1, "AdWordsJobs"], ["javascript", 1, "Stud_Richmond"], ["javascript", 1, "Go_Freelancer"], ["javascript", 1, "bulkanevcimen"], ["javascript", 1, "tonytamps"], ["javascript", 1, "CounilLaurent"], ["javascript", 2, "LissaRabinowitz"], ["javascript", 1, "DesignLearnBot"], ["javascript", 1, "Best_Gadgets_4U"], ["javascript", 1, "rjaviervega"], ["javascript", 1, "emGhost_"], ["javascript", 18, "js_digest"], ["javascript", 2, "symfony_jobs"], ["javascript", 1, "MVP_Armagan"], ["javascript", 1, "imarshut"], ["javascript", 4, "ameanmbot"], ["javascript", 1, "wp_digest"], ["javascript", 1, "wp_portugal"], ["javascript", 1, "EmotiCodeDotNet"], ["javascript", 1, "cveksitron"], ["javascript", 3, "PHPHire"], ["javascript", 4, "html5_4_all"], ["javascript", 1, "Best_WordPress_"]]', '[["php", 1, "webdevgigs"], ["php", 1, "BriansWebWorks"], ["php", 1, "suyatitech"], ["php", 1, "ali7amdi"], ["php", 1, "MikeMoraRocks"], ["php", 1, "nicklevett"], ["php", 1, "NewEraDesign"], ["php", 1, "BoylemeLEon"], ["php", 1, "ChePelletier"], ["php", 1, "PermataHousePro"], ["php", 1, "StackCareers"], ["php", 1, "manuelvilella"], ["php", 1, "UKPHPJobs"], ["php", 1, "LissaRabinowitz"], ["php", 3, "symfony_jobs"], ["php", 1, "WebDesignBetter"], ["php", 1, "AgenteNotFound"], ["php", 1, "goetas_asmir"], ["php", 1, "MVP_Armagan"], ["php", 5, "js_digest"], ["php", 1, "FranziskaElle"], ["php", 1, "mrvijayakumar"], ["php", 3, "MaickeyArlin"], ["php", 1, "willcantrell123"], ["php", 2, "PHPHire"]]', '[["python", 1, "marthiaflo"], ["python", 1, "tanyaqiin"], ["python", 1, "biicode"], ["python", 1, "js_digest"], ["python", 9, "artwisanggeni"], ["python", 1, "theuni"], ["python", 1, "SeyerleRose15"], ["python", 1, "CyrilClaire2"], ["python", 1, "PHPHire"], ["python", 1, "giovannibajo"]]', '[["java", 1, "softwaremill"], ["java", 1, "vacatures_java"], ["java", 1, "danielbartl"], ["java", 1, "ameanmbot"], ["java", 1, "nl_zoekjijwerk"], ["java", 1, "FranziskaElle"], ["java", 1, "mzkred"]]', '[["ruby", 1, "jeffreydemun"], ["ruby", 2, "RailsJobsCom"], ["ruby", 1, "prcaen"], ["ruby", 1, "lulalala_it"], ["ruby", 1, "js_digest"], ["ruby", 1, "moises_macia"], ["ruby", 1, "IleniaGiagnoni"], ["ruby", 1, "rates_exchange"], ["ruby", 1, "PHPHire"], ["ruby", 1, "stevewalkr"]]', '[["visual_basic", 1, "VB_bingb"]]', '[["csharp", 1, "js_digest"], ["csharp", 1, "StackCareers"], ["csharp", 1, "PHPHire"]]', '[["swift", 1, "blueupbeacons"], ["swift", 1, "zmarkan"]]']
# SQL STRING: SELECT hashtag, HashTagCount, screen_name
# FROM (SELECT hashtag, screen_name, HashTagCount, rank() OVER (PARTITION BY hashtag ORDER BY HashTagCount DESC, screen_name) AS pos
# FROM (SELECT hashtag, screen_name, COUNT(hashtag) as HashTagCount
# FROM (SELECT screen_name, unnest(hashtags) as hashtag FROM massive) as unwrap
# WHERE
# hashtag = %s
# OR
# hashtag = %s
# GROUP BY screen_name, hashtag
# ORDER BY hashtag, HashTagCount DESC
# ) as countedhashtags
# ) as ss
# WHERE pos = 1
# ORDER BY hashtag, HashTagCount DESC





def _query_tweet_ids():
    sql = """SELECT screen_name, tweet_text FROM tweets;
    ORDER BY tweet_id DESC
    LIMIT 1;"""
    return (sql, None)

def _save_tweets():
    return ("""
            INSERT INTO tweets(
                tweet_id, screen_name, tweet_url, tweet_text, hashtags, location, retweet_count)

            VALUES(
                %s, %s, %s, %s, %s, %s, %s); """, [])

def _save_users():
    return("""INSERT INTO users (screen_name, account_url,
                                tweet_count, last_tweet_timestamp)
                 VALUES (%s, %s, %s, %s); """,[])

def _save_filters():
    return ("""INSERT INTO filters( filter_name,
                                                last_tweet_timestamp,
                                                tweet_count)
                   VALUES (%s, %s, %s); """,[])

def save_user_filter_join():
    return ("""INSERT INTO user_filter_join( screen_name,
                                                filter_name,
                                                tweet_count,
                                                first_tweet_timestamp,
                                                last_tweet_timestamp)
                   VALUES (%s, %s, %s, %s, %s); """,[])



def get_query_results(chart_string, args=None, need_fetch=True):
    if args is None:
        args = QUERY_STRINGS[chart_string][1]
    if chart_string == 'fetch_popular_users':
        return _query_popular_users()
    else:
        print "------->"
        print chart_string
        print QUERY_STRINGS[chart_string][0]
        print "------->"
        return _execute_query(
            QUERY_STRINGS[chart_string][0],
            args,
            need_fetch)
