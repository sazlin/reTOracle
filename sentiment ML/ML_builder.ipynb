{
 "metadata": {
  "name": "",
  "signature": "sha256:06c3bda786f78a6fb3ff45beae32dc4b05dda7ff24ac74e58be07f6d6b3a18d9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.linear_model import LogisticRegression as LR\n",
      "from string import maketrans\n",
      "import pandas as pd\n",
      "from pandas import DataFrame, read_csv, read_excel, concat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_vocab(n, training_samples = 1000, vocab=None):\n",
      "    if not vocab:\n",
      "        vocab = []\n",
      "    with open('stopwords.txt') as stop_words:\n",
      "        stop_words = {line.strip().lower() for line in stop_words if line!='\\n'} \n",
      "    words = {}    \n",
      "    tweets = []\n",
      "    for tweet in train_df['SentimentText'][0:training_samples]:\n",
      "        clean_tweet = tweet.translate(maketrans('?!,.', '    '))\n",
      "        tweets.extend(clean_tweet.strip().lower().split())\n",
      "    for word in tweets:\n",
      "        if word not in stop_words:\n",
      "            for happy in happyface:\n",
      "                if happy in word:\n",
      "                    word = 'happyface'\n",
      "                    break\n",
      "            for sad in sadface:\n",
      "                if sad in word:\n",
      "                    word = 'sadface'\n",
      "                    break\n",
      "            if word.isalnum() and len(word)>1:    \n",
      "                if words.get(word, False):\n",
      "                    words[word] += 1\n",
      "                else:\n",
      "                    words[word] = 1\n",
      "                        \n",
      "    vocab = sorted(words.iteritems(), key=lambda x: x[1], reverse=True)\n",
      "    vocab = [tup[0] for tup in vocab]\n",
      "    return vocab[:n]\n",
      "\n",
      "def vectorize(vocab, tweet):\n",
      "    vector = np.zeros(len(vocab))\n",
      "    word_list = []\n",
      "    clean_tweet = tweet.translate(maketrans('?!,.', '    '))\n",
      "    word_list.extend(clean_tweet.strip().lower().split())\n",
      "\n",
      "    for word in word_list:\n",
      "        try:\n",
      "            vector[vocab.index(word)] += 1\n",
      "        except ValueError:\n",
      "            pass\n",
      "    return vector\n",
      "\n",
      "def make_classifier(vocab, training_samples = 1000):\n",
      "    tweet_array = np.zeros((training_samples, len(vocab)))\n",
      "    for index, tweet in enumerate(train_df['SentimentText'][0:training_samples]):\n",
      "        tweet_array[index] = vectorize(vocab, tweet)\n",
      "    output = train_df['Sentiment'][0:training_samples]\n",
      "    clf = SVC(kernel='linear')\n",
      "    clf.fit(tweet_array, np.asarray(output))\n",
      "    return clf\n",
      "\n",
      "def test_classifier(vocab, classifier, training_samples, test_samples = 400):\n",
      "    test_array = np.zeros((test_samples, len(vocab)))\n",
      "    for index, tweet in enumerate(train_df['SentimentText'][training_samples:test_samples]):\n",
      "        test_array[index] = vectorize(vocab,tweet)\n",
      "    predictions = classifier.predict(test_array)\n",
      "    correct, wrong = 0,0\n",
      "    for index, predict in enumerate(predictions):\n",
      "        if predict == train_df['Sentiment'][index+training_samples]:\n",
      "            correct += 1\n",
      "        else:\n",
      "            wrong += 1\n",
      "    print (correct, wrong)\n",
      "    print 'Percentage {}'.format(1.0*correct/(correct+wrong))\n",
      "\n",
      "def PCA_analysis(vocab, training_samples = 1000):\n",
      "    tweet_array = np.zeros((training_samples, len(vocab)))\n",
      "    for index, tweet in enumerate(train_df['SentimentText'][0:training_samples]):\n",
      "        tweet_array[index] = vectorize(vocab, tweet)\n",
      "    pca = PCA(n_components=2)\n",
      "    pca.fit(tweet_array)\n",
      "    print(pca.explained_variance_ratio_)\n",
      "    print(pca.components_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ML_build()\n",
      "    with open('happyface.txt') as happyface:\n",
      "        happyface = [line.strip() for line in happyface if line!='\\n']\n",
      "        sadface = [line.strip()[::-1] for line in happyface if line!='\\n']\n",
      "\n",
      "    train_df = read_csv('Small_sample.csv')\n",
      "    train_df = train_df.ix[:,['Sentiment','SentimentText']]\n",
      "\n",
      "    vocab = build_vocab(5000, 2500)\n",
      "    classifier = make_classifier(vocab, training_samples = 2500)\n",
      "    test_classifier(vocab, classifier, 2500, 400)\n",
      "    return classifier, vocab\n",
      "\n",
      "def Predict_Incoming(tweet)\n",
      "    ML_clf, vocab = ML_build()\n",
      "    ML_clf.predict(vectorize(vocab, tweet))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.decision_function(vectorize(vocab,'Hi I am super happy :)'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 205,
       "text": [
        "array([[ 1.12513478]])"
       ]
      }
     ],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PCA_analysis(vocab, 2500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.01098302  0.01057203]\n",
        "[[  2.34374876e-01   1.26850290e-02   6.87871082e-03 ...,  -9.09732606e-05\n",
        "   -9.21806925e-05  -3.40161647e-04]\n",
        " [ -8.85786837e-01  -3.88939874e-03   5.96029603e-02 ...,   4.85660328e-04\n",
        "    4.92361966e-04   7.92779590e-04]]\n"
       ]
      }
     ],
     "prompt_number": 202
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}